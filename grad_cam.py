#grad_cam.py
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt
import cv2
from skimage.measure import regionprops, label, shannon_entropy

# -----------------------------
# 1Ô∏è‚É£ Load Model
# -----------------------------
model_path = r"D:\XAI_Feature_Extraction\resnet50_model.h5"  # path to your trained model
model = load_model(model_path)

# -----------------------------
# 2Ô∏è‚É£ Load Image
# -----------------------------
img_path = r"D:\XAI_Feature_Extraction\reduce_data\neutrophil\BNE_5294_0_1206.jpg"
img = image.load_img(img_path, target_size=(224, 224))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = tf.keras.applications.vgg16.preprocess_input(x)

# -----------------------------
# 3Ô∏è‚É£ Prediction
# -----------------------------
preds = model.predict(x)
preds = np.squeeze(preds)

print("Predictions shape:", preds.shape)

pred_class = int(np.argmax(preds))
confidence = float(preds[pred_class]) * 100

# Automatically match number of outputs
if len(preds) != 5:
    print(f"‚ö†Ô∏è Model output size {len(preds)} != 5 (check training data!)")

# Adjust label list dynamically if mismatch
class_labels = ['basophil', 'eosinophil', 'lymphocyte', 'monocyte', 'neutrophil'][:len(preds)]
pred_label = class_labels[pred_class]
print(f"‚úÖ Predicted class: {pred_label} ({confidence:.2f}%)")

# -----------------------------
# 4Ô∏è‚É£ Grad-CAM
# -----------------------------
last_conv_layer_name = [layer.name for layer in model.layers if 'conv' in layer.name][-1]
grad_model = tf.keras.models.Model(
    [model.inputs],
    [model.get_layer(last_conv_layer_name).output, model.output]
)

with tf.GradientTape() as tape:
    conv_outputs, predictions = grad_model(x)
    loss = predictions[:, pred_class]

grads = tape.gradient(loss, conv_outputs)
pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
conv_outputs = conv_outputs[0]

heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_outputs), axis=-1)
heatmap = np.maximum(heatmap, 0)
heatmap /= np.max(heatmap)

# Resize heatmap to match original image
img_original = cv2.imread(img_path)
img_original = cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB)
heatmap_resized = cv2.resize(heatmap, (img_original.shape[1], img_original.shape[0]))

# -----------------------------
# 5Ô∏è‚É£ Identify Most Influential Region
# -----------------------------
heatmap_255 = np.uint8(255 * heatmap_resized)
_, thresh = cv2.threshold(heatmap_255, 180, 255, cv2.THRESH_BINARY)
labeled = label(thresh)
regions = regionprops(labeled)

if len(regions) > 0:
    regions = sorted(regions, key=lambda r: r.area, reverse=True)
    most_important_region = regions[0]

    # Extract region properties
    centroid = most_important_region.centroid
    area = most_important_region.area
    solidity = most_important_region.solidity
    eccentricity = most_important_region.eccentricity
    entropy = shannon_entropy(heatmap_resized[int(centroid[0])-10:int(centroid[0])+10,
                                              int(centroid[1])-10:int(centroid[1])+10])

    # Bounding box for visualization
    minr, minc, maxr, maxc = most_important_region.bbox
    region_score = np.mean(heatmap_resized[minr:maxr, minc:maxc])
    gradcam_corr = 0.185  # sample correlation for illustration

    # -----------------------------
    # 6Ô∏è‚É£ Dynamic Region Explanation
    # -----------------------------
    if entropy > 4:
        texture_desc = "highly textured and complex"
    elif entropy > 2:
        texture_desc = "moderately textured"
    else:
        texture_desc = "smooth and uniform"

    if solidity < 0.6:
        shape_desc = "irregular shape with scattered boundaries"
    else:
        shape_desc = "compact and well-defined region"

    if eccentricity > 0.7:
        form_desc = "elongated structure"
    else:
        form_desc = "rounded structure"

    region_explanation = f"""
üß© **Explanation of Most Influential Region**
- Most Important Region ID: 1
- Score: {region_score:.4f}
- Area: {area:.1f}
- Centroid: ({centroid[1]:.1f}, {centroid[0]:.1f})
- Solidity: {solidity:.3f}
- Eccentricity: {eccentricity:.3f}
- Entropy: {entropy:.3f}
- Feature Most Responsible: Entropy

üß† **Interpretation:**
The region appears {texture_desc}, with {shape_desc} and a {form_desc}.
This morphological pattern aligns with Grad-CAM activations (correlation = {gradcam_corr:.3f}),
indicating that the model focuses on this high-response area to classify the image as **{pred_label}**.
"""

    print(region_explanation)

    # -----------------------------
    # 7Ô∏è‚É£ Overlay Grad-CAM Visualization
    # -----------------------------
    gradcam_img = cv2.applyColorMap(heatmap_255, cv2.COLORMAP_JET)
    superimposed_img = cv2.addWeighted(img_original, 0.6, gradcam_img, 0.4, 0)
    cv2.rectangle(superimposed_img, (minc, minr), (maxc, maxr), (0, 255, 0), 2)

    plt.figure(figsize=(7, 7))
    plt.title(f"Grad-CAM: Influential Region\n{pred_label} ({confidence:.1f}%)")
    plt.imshow(superimposed_img)
    plt.axis("off")
    plt.show()

else:
    print("‚ö†Ô∏è No highly activated region found.")
